# Speech Recognition Portal

## üìå –û–ø–∏—Å–∞–Ω–∏–µ / Description

### üá∑üá∫ –û–ø–∏—Å–∞–Ω–∏–µ
**Speech Recognition Portal** ‚Äì —ç—Ç–æ –≤–µ–±-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏ –∏–∑ –∞—É–¥–∏–æ- –∏ –≤–∏–¥–µ–æ—Ñ–∞–π–ª–æ–≤. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ñ–æ—Ä–º–∞—Ç—ã `.wav`, `.mp3`, `.mp4` –∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –º–æ–¥–µ–ª—å Whisper –æ—Ç OpenAI –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ –∏ pyannote/speaker-diarization –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Å–ø–∏–∫–µ—Ä–æ–≤. –ü—Ä–æ–µ–∫—Ç —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—è–µ—Ç—Å—è –ø–æ–¥ –ª–∏—Ü–µ–Ω–∑–∏–µ–π **GPL-3.0**.

### üá¨üáß Description
**Speech Recognition Portal** is a web application for automatic speech recognition from audio and video files. It supports `.wav`, `.mp3`, `.mp4` formats and uses OpenAI's Whisper model for transcription and pyannote/speaker-diarization for speaker recognition. The project is distributed under the **GPL-3.0** license.

---

## üöÄ –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ / Features

### üá∑üá∫ –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏
- –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ñ–∞–π–ª–æ–≤ –±–æ–ª—å—à–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ (`.wav`, `.mp3`, `.mp4`)
- –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è –ø–æ—Ä—è–¥–∫–∞ —Ñ–∞–π–ª–æ–≤ –ø–µ—Ä–µ–¥ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ–º
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ñ–∞–π–ª–æ–≤ –≤ –æ–¥–∏–Ω
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∞—É–¥–∏–æ –≤ —Ñ–æ—Ä–º–∞—Ç `.wav`
- **–ù–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º —Å–ø–∏–∫–µ—Ä–æ–≤:**
  1. –°–Ω–∞—á–∞–ª–∞ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è —Å–ø–∏–∫–µ—Ä–æ–≤ —Å —Ç–æ—á–Ω—ã–º–∏ —Ç–∞–π–º–∏–Ω–≥–∞–º–∏
  2. –ó–∞—Ç–µ–º –∫–∞–∂–¥—ã–π —Å–µ–≥–º–µ–Ω—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ—Ç—Å—è –æ—Ç–¥–µ–ª—å–Ω–æ
  3. –†–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç—Å—è —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Ç–æ—á–Ω—ã—Ö –≥—Ä–∞–Ω–∏—Ü –≤—Ä–µ–º–µ–Ω–∏
- –ü—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º —ç—Ç–∞–ø–æ–≤
- –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –≤ `.txt` —Å —É–∫–∞–∑–∞–Ω–∏–µ–º –≥–æ–≤–æ—Ä—è—â–∏—Ö
- –ó–∞–ø—É—Å–∫ –≤ `Docker` —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π CPU
- REST API (–µ—Å–ª–∏ –ø—Ä–∏–º–µ–Ω–∏–º–æ)
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã

### üá¨üáß Features
- Upload multiple large files (`.wav`, `.mp3`, `.mp4`)
- Ability to change file order before merging
- Automatic merging of multiple files into one
- Automatic audio conversion to `.wav` format
- **New speaker-first approach:**
  1. Speaker segmentation with precise timings is determined first
  2. Each segment is then transcribed separately
  3. Results are merged while preserving exact time boundaries
- Processing progress bar with stage display
- Download result in `.txt` with speaker indication
- Docker deployment with CPU support
- REST API (if applicable)
- Automatic tests

---

## üîÑ –ù–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º —Å–ø–∏–∫–µ—Ä–æ–≤ / New Speaker-First Approach

### üá∑üá∫ –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –Ω–æ–≤–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞
- **–¢–æ—á–Ω–æ—Å—Ç—å —Ç–∞–π–º–∏–Ω–≥–æ–≤**: –ö–∞–∂–¥—ã–π —Å–µ–≥–º–µ–Ω—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ—Ç—Å—è –æ—Ç–¥–µ–ª—å–Ω–æ, —á—Ç–æ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç —Ç–æ—á–Ω—ã–µ –≥—Ä–∞–Ω–∏—Ü—ã –≤—Ä–µ–º–µ–Ω–∏
- **–õ—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è**: –ö–æ—Ä–æ—Ç–∫–∏–µ —Å–µ–≥–º–µ–Ω—Ç—ã —á–∞—Å—Ç–æ —Ä–∞—Å–ø–æ–∑–Ω–∞—é—Ç—Å—è –ª—É—á—à–µ, —á–µ–º –¥–ª–∏–Ω–Ω—ã–µ
- **–ß–µ—Ç–∫–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ —Å–ø–∏–∫–µ—Ä–æ–≤**: –ù–µ—Ç —Å–º–µ—à–∏–≤–∞–Ω–∏—è —Ä–µ—á–∏ —Ä–∞–∑–Ω—ã—Ö —Å–ø–∏–∫–µ—Ä–æ–≤ –≤ –æ–¥–Ω–æ–º —Å–µ–≥–º–µ–Ω—Ç–µ
- **Fallback –º–µ—Ö–∞–Ω–∏–∑–º**: –ï—Å–ª–∏ –Ω–µ —É–¥–∞–µ—Ç—Å—è –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Å–ø–∏–∫–µ—Ä–æ–≤, —Å–∏—Å—Ç–µ–º–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ–∫–ª—é—á–∞–µ—Ç—Å—è –Ω–∞ –ø–æ–ª–Ω—É—é —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—é

### üá¨üáß Benefits of the new approach
- **Timing accuracy**: Each segment is transcribed separately, ensuring precise time boundaries
- **Better recognition quality**: Short segments are often recognized better than long ones
- **Clear speaker separation**: No mixing of different speakers' speech in one segment
- **Fallback mechanism**: If speaker detection fails, the system automatically switches to full transcription

### üá∑üá∫ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞
```bash
python test_speaker_first_approach.py uploads/test_audio.wav
```

### üá¨üáß Testing the new approach
```bash
python test_speaker_first_approach.py uploads/test_audio.wav
```

–ü–æ–¥—Ä–æ–±–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è: [SPEAKER_FIRST_APPROACH.md](SPEAKER_FIRST_APPROACH.md)

Detailed documentation: [SPEAKER_FIRST_APPROACH.md](SPEAKER_FIRST_APPROACH.md)

---

## üõ†Ô∏è –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ –∑–∞–ø—É—Å–∫ / Installation and Setup

### üá∑üá∫ –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è
- Docker –∏ Docker Compose
- –ú–∏–Ω–∏–º—É–º 4GB RAM
- –ü—Ä–æ—Ü–µ—Å—Å–æ—Ä —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π AVX2 (–¥–ª—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏)
- –ê–∫–∫–∞—É–Ω—Ç –Ω–∞ Hugging Face —Å —Ç–æ–∫–µ–Ω–æ–º –¥–æ—Å—Ç—É–ø–∞

### üá¨üáß Requirements
- Docker and Docker Compose
- Minimum 4GB RAM
- CPU with AVX2 support (for optimal performance)
- Hugging Face account with access token

### üá∑üá∫ –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –Ω–∞ Hugging Face

–î–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ–º —Å–ø–∏–∫–µ—Ä–æ–≤ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ:

1. **–°–æ–∑–¥–∞—Ç—å –∞–∫–∫–∞—É–Ω—Ç –Ω–∞ Hugging Face:**
   - –ü–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ https://huggingface.co/join
   - –ó–∞–ø–æ–ª–Ω–∏—Ç–µ —Ñ–æ—Ä–º—É —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏
   - –ü–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç–µ email

2. **–ü–æ–ª—É—á–∏—Ç—å —Ç–æ–∫–µ–Ω –¥–æ—Å—Ç—É–ø–∞:**
   - –í–æ–π–¥–∏—Ç–µ –≤ –∞–∫–∫–∞—É–Ω—Ç –Ω–∞ https://huggingface.co
   - –ü–µ—Ä–µ–π–¥–∏—Ç–µ –≤ Settings ‚Üí Access Tokens: https://huggingface.co/settings/tokens
   - –ù–∞–∂–º–∏—Ç–µ "New token"
   - –í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–∫–µ–Ω–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "speech-recognition")
   - –í—ã–±–µ—Ä–∏—Ç–µ —Ä–æ–ª—å "Read"
   - –ù–∞–∂–º–∏—Ç–µ "Generate token"
   - –°–∫–æ–ø–∏—Ä—É–π—Ç–µ —Ç–æ–∫–µ–Ω (–æ–Ω –ø–æ–Ω–∞–¥–æ–±–∏—Ç—Å—è –ø–æ–∑–∂–µ)

3. **–ü—Ä–∏–Ω—è—Ç—å —É—Å–ª–æ–≤–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π:**
   –ü–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ —ç—Ç–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏ –Ω–∞–∂–º–∏—Ç–µ "Accept":
   - https://huggingface.co/pyannote/speaker-diarization
   - https://huggingface.co/pyannote/segmentation
   - https://huggingface.co/pyannote/embedding

### üá¨üáß Hugging Face Registration

For speaker recognition functionality:

1. **Create Hugging Face account:**
   - Go to https://huggingface.co/join
   - Fill out the registration form
   - Confirm your email

2. **Get access token:**
   - Log in to https://huggingface.co
   - Go to Settings ‚Üí Access Tokens: https://huggingface.co/settings/tokens
   - Click "New token"
   - Enter token name (e.g., "speech-recognition")
   - Select role "Read"
   - Click "Generate token"
   - Copy the token (you'll need it later)

3. **Accept model usage terms:**
   Go to these pages and click "Accept":
   - https://huggingface.co/pyannote/speaker-diarization
   - https://huggingface.co/pyannote/segmentation
   - https://huggingface.co/pyannote/embedding

### üá∑üá∫ –ë—ã—Å—Ç—Ä—ã–π –∑–∞–ø—É—Å–∫
1. –ö–ª–æ–Ω–∏—Ä—É–π—Ç–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π:
```bash
git clone https://github.com/biguxuzz/VoskRecognition.git
cd VoskRecognition
```

2. –°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª `.env` —Å –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–º–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏:
```bash
HF_TOKEN=your_huggingface_token_here
UPLOAD_FOLDER=/data/uploads
RESULT_FOLDER=/data/results
```

3. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ:
```bash
docker-compose up --build
```

4. –û—Ç–∫—Ä–æ–π—Ç–µ –±—Ä–∞—É–∑–µ—Ä –∏ –ø–µ—Ä–µ–π–¥–∏—Ç–µ –ø–æ –∞–¥—Ä–µ—Å—É: `http://localhost:5000`

### üá¨üáß Quick Start
1. Clone the repository:
```bash
git clone https://github.com/biguxuzz/VoskRecognition.git
cd VoskRecognition
```

2. Create `.env` file with required variables:
```bash
HF_TOKEN=your_huggingface_token_here
UPLOAD_FOLDER=/data/uploads
RESULT_FOLDER=/data/results
```

3. Start the application:
```bash
docker-compose up --build
```

4. Open your browser and go to: `http://localhost:5000`

---

## üìã –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è / Configuration

### üá∑üá∫ –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
- `HF_TOKEN` - —Ç–æ–∫–µ–Ω Hugging Face –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ –º–æ–¥–µ–ª—è–º
- `UPLOAD_FOLDER` - –ø–∞–ø–∫–∞ –¥–ª—è –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
- `RESULT_FOLDER` - –ø–∞–ø–∫–∞ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

### üá¨üáß Environment Variables
- `HF_TOKEN` - Hugging Face token for model access
- `UPLOAD_FOLDER` - folder for uploaded files
- `RESULT_FOLDER` - folder for results

---

## üìù –õ–∏—Ü–µ–Ω–∑–∏—è / License

–≠—Ç–æ—Ç –ø—Ä–æ–µ–∫—Ç —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—è–µ—Ç—Å—è –ø–æ–¥ –ª–∏—Ü–µ–Ω–∑–∏–µ–π **GPL-3.0**. –°–º. —Ñ–∞–π–ª `LICENSE` –¥–ª—è –ø–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–µ–π.

This project is distributed under the **GPL-3.0** license. See the `LICENSE` file for details.

---

## ü§ù –í–∫–ª–∞–¥ –≤ –ø—Ä–æ–µ–∫—Ç / Contributing

–ú—ã –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤—É–µ–º –≤–∫–ª–∞–¥—ã –≤ –ø—Ä–æ–µ–∫—Ç! –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–æ–∑–¥–∞–≤–∞–π—Ç–µ issues –∏ pull requests.

We welcome contributions to the project! Please create issues and pull requests.

---

## üìß –ö–æ–Ω—Ç–∞–∫—Ç—ã / Contacts

- **GitHub:** [biguxuzz](https://github.com/biguxuzz)
- **Telegram:** [@biguxuzz](https://t.me/biguxuzz)
- **Email:** gorp@1cgst.ru