# Новый подход: Приоритет спикеров

## Проблема

В предыдущей версии системы распознавание работало следующим образом:
1. Сначала выполнялась полная транскрибация всего аудио
2. Затем определялись сегменты спикеров
3. Происходило сопоставление таймингов транскрибации с сегментами спикеров

Это приводило к проблеме: тайминги транскрибации часто "поглощали" ответы спикеров в один промежуток, что снижало точность определения того, кто именно говорил в конкретный момент времени.

## Решение

Новый подход `SpeakerFirstTranscriptionManager` работает в обратном порядке:

### 1. Определение сегментов спикеров (20% прогресса)
- Используется `SpeakerRecognizer` для определения точных временных границ каждого спикера
- Получаем список сегментов с точными таймингами начала и окончания

### 2. Транскрибация отдельных сегментов (70% прогресса)
- Для каждого сегмента спикера:
  - Извлекается соответствующий фрагмент аудио с помощью `ffmpeg`
  - Выполняется транскрибация только этого фрагмента
  - Результат связывается с конкретным спикером и таймингами

### 3. Форматирование результатов (5% прогресса)
- Объединение всех результатов в единый формат
- Сохранение точных таймингов для каждого спикера

## Преимущества нового подхода

1. **Точность таймингов**: Каждый сегмент транскрибируется отдельно, что обеспечивает точные границы времени
2. **Лучшее качество распознавания**: Короткие сегменты часто распознаются лучше, чем длинные
3. **Четкое разделение спикеров**: Нет смешивания речи разных спикеров в одном сегменте
4. **Fallback механизм**: Если не удается определить спикеров, система автоматически переключается на полную транскрибацию

## Использование

### В коде
```python
from app.speaker_first_transcription_manager import SpeakerFirstTranscriptionManager

# Создаем менеджер
transcription_manager = SpeakerFirstTranscriptionManager()

# Обрабатываем аудио
def progress_callback(progress):
    print(f"Progress: {progress:.1f}%")

result = transcription_manager.process_audio("audio.wav", progress_callback)
```

### Тестирование
```bash
python test_speaker_first_approach.py uploads/test_audio.wav
```

## Формат результата

Результат имеет следующий формат:
```
[00:00:05] [SPEAKER_0] Привет, как дела?
[00:00:08] [SPEAKER_1] Привет! Все хорошо, спасибо.
[00:00:12] [SPEAKER_0] Отлично, рад это слышать.
```

Где:
- `[HH:MM:SS]` - точное время начала сегмента
- `[SPEAKER_X]` - идентификатор спикера
- Текст - транскрибированная речь

## Технические детали

### Извлечение сегментов
Используется `ffmpeg` с параметрами:
- `-ss` - время начала сегмента
- `-t` - длительность сегмента
- `-acodec pcm_s16le` - кодек для совместимости
- `-ar 16000` - частота дискретизации 16kHz
- `-ac 1` - монофонический звук

### Обработка ошибок
- Если сегмент не удается транскрибировать, добавляется метка `[Ошибка транскрибации]`
- Если не удается определить спикеров, используется fallback к полной транскрибации
- Временные файлы автоматически очищаются после обработки

## Производительность

Новый подход может быть медленнее из-за:
- Необходимости обработки множества отдельных сегментов
- Дополнительных операций извлечения аудио

Однако качество результата значительно выше, что оправдывает увеличение времени обработки. 