# Внутренний портал по распознаванию лекций и совещаний

## 1. Введение

Целью разработки является создание внутреннего портала для автоматического распознавания речи из аудио- и видеофайлов, конвертации их в текст и предоставления пользователю результата в виде текстового файла.

Данный проект будет распространяться под лицензией **GPL-3.0**. Это означает, что исходный код должен быть открыт, а производные работы также должны соблюдать условия данной лицензии.

## 2. Функциональные требования

### 2.1. Загрузка файлов

- Пользователь должен иметь возможность загружать файлы большого размера через веб-интерфейс.
- Пользователь должен иметь возможность загружать несколько файлов, и менять их порядок перед объедиением в один файл.
- Поддерживаемые форматы файлов для загрузки: `.wav`, `.mp3`, `.mp4`.
- Если файлов загружено несколько то сначала они должны автоматически объединиться в один.
- Загруженные файлы должны автоматически конвертироваться в формат `.wav`, если они изначально в формате `.mp3` или `.mp4`.

### 2.2. Начало процесса распознавания

- После получения единого файла `.wav` начинается процесс распознавания, который состоит из двух этапов:
  1. Транскрибация речи:
     - Конвертация файла (если необходимо)
     - Разделение на фрагменты (если требуется)
     - Распознавание речи с таймкодами
  2. Распознавание спикеров:
     - Анализ аудио с помощью модели pyannote/speaker-diarization
     - Сопоставление сегментов речи с идентифицированными спикерами
     - Формирование финального текста с указанием говорящих
- Пользователь видит индикатор выполнения процесса в виде прогресс-бара, отображающий текущий этап и подэтап обработки.

### 2.3. Вывод результата

- После завершения процесса распознавания пользователь должен иметь возможность скачать текстовый файл с результатом (`.txt`).
- Текстовый файл должен содержать транскрибированные данные, разбитые по абзацам.

## 3. Технические требования

### 3.1. Технологический стек

- **Язык программирования**: Python 3.9+
- **Фреймворк для веб-интерфейса**: Flask 2.0+
- **Библиотеки для работы с аудио и распознавания речи**:
  - `openai-whisper` – для транскрибации
  - `torch` и `torchaudio` – для работы с нейронными сетями
  - `numpy` – для обработки данных
  - `ffmpeg-python` – для конвертации файлов
  - `pyannote.audio` – для сегментации аудио
  - `speechbrain` – для дополнительной обработки речи
  - `transformers` – для работы с языковыми моделями

### 3.2. Обработка файлов

- Загруженные файлы должны сохраняться в директории `uploads/`.
- Результаты распознавания сохраняются в директории `results/`.
- При загрузке `.mp3` и `.mp4` файлы должны конвертироваться в `.wav` с частотой дискретизации 16kHz, моно.
- Для конвертации используется `ffmpeg`.

### 3.3. Запуск и развертывание

- Приложение упаковано в **Docker-контейнер**.
- Docker-контейнер содержит все необходимые зависимости, включая CUDA для GPU-ускорения.
- Конфигурация сборки описана в `Dockerfile` и `docker-compose.yml`.
- Переменные окружения хранятся в файле `.env`.

### 3.4. Используемые модели

- Для транскрибации используется модель **Whisper** от OpenAI.
- Для распознавания спикеров используется модель **pyannote/speaker-diarization** с Hugging Face.
- Дополнительно используются модели:
  - `pyannote.audio` для сегментации аудио
  - `speechbrain` для улучшения качества распознавания

## 4. Требования к интерфейсу

- Веб-интерфейс минималистичный и удобный.
- Основные элементы интерфейса:
  - Поле для загрузки файла
  - Кнопка "Начать распознавание"
  - Прогресс-бар выполнения
  - Кнопка "Скачать результат"
- Все процессы сопровождаются понятными статусами.

## 5. Автоматическое тестирование

- Проект содержит автоматические тесты.
- Тесты покрывают:
  - Загрузку файла
  - Конвертацию аудио
  - Запуск процесса распознавания
  - Корректность полученного текста
  - Отображение результатов в интерфейсе
- Используемые инструменты тестирования:
  - `pytest` – для unit-тестов
  - `selenium` – для тестирования интерфейса
  - `pytest-flask` – для тестирования Flask-приложения

## 6. Деплой и эксплуатация

- Портал работает внутри корпоративной сети.
- Развертывание осуществляется через Docker Compose.
- Поддерживается работа как на CPU, так и на GPU.

## 7. Документация

- Проект содержит:
  - README.md с инструкцией по установке и запуску
  - Структуру проекта в project_structure.txt
  - Документацию по API в соответствующих файлах

## 8. Лицензия

- Код проекта распространяется под лицензией **GPL-3.0**.
- Любые изменения и производные проекты должны соблюдать условия данной лицензии.
- В исходном коде присутствует лицензия в виде заголовков в файлах и отдельного LICENSE-файла в корне репозитория.

